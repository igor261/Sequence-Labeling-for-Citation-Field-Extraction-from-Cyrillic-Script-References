{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform \"XML 1.1\" to \"TEI\"\n",
    "\n",
    "There are two steps to achieve this:\n",
    "\n",
    "* Extract data from the XML 1.1 Files\n",
    "* Write this data in a TEI format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages & define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment, tostring\n",
    "from xml.dom import minidom\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_path(d):\n",
    "    # Return full path of all files & directories in directory\n",
    "    list_full_path = []\n",
    "    for path in os.listdir(d):\n",
    "        full_path = os.path.join(d, path)\n",
    "        list_full_path.append(full_path)\n",
    "    return list_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_ = \"D:/manual_anno\"\n",
    "dir_ = \".\\Sequence-Labeling-for-Reference-Parsing-of-Cyrillic-Script-Scholarly-Data\\Real_annotated_data\\manual_anno_xml1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_paper_id = []\n",
    "for path in listdir_path(dir_):\n",
    "    pdf = str(path).split(\"\\\\\")[1]\n",
    "    core_id = pdf.split(\".\")[0].split(\"_\")[2]\n",
    "    list_paper_id.append(core_id)\n",
    "list_paper_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = [f for f in listdir_path(dir_)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for path in files:\n",
    "    print(path)\n",
    "    core_id = str(path).split(\"\\\\\")[1].split(\".\")[0].split(\"_\")[2]\n",
    "    \n",
    "    # get the xml1.1 annotation\n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    tokens_doc = []\n",
    "    labels_doc = []\n",
    "\n",
    "    for lt in root.findall(\"{http:///webanno/custom.ecore}Label\"):\n",
    "        label = lt.attrib[\"value\"]\n",
    "        token = root.findall(\"{http:///uima/cas.ecore}Sofa\")[0].attrib[\"sofaString\"][int(lt.attrib[\"begin\"]) : int(lt.attrib[\"end\"])]\n",
    "    #     print(\"Token \" + root.findall(\"{http:///uima/cas.ecore}Sofa\")[0].attrib[\"sofaString\"][int(lt.attrib[\"begin\"]) : int(lt.attrib[\"end\"])] + \" hat Label \" + label)\n",
    "    #     d[token]=(label)\n",
    "        labels_doc.append(label)\n",
    "        tokens_doc.append(re.sub(\"\\n\",\"\",re.sub(\"  \", \" \",str(token).strip(' \\t\\n'))))\n",
    "        \n",
    "    prev_label = None\n",
    "    prev_token = None\n",
    "    count_ref = 0\n",
    "    sequence = []\n",
    "    label_seq = []\n",
    "    all_label_seq = []\n",
    "    all_seq = []\n",
    "    i=0\n",
    "    for l , t in zip(labels_doc , tokens_doc):\n",
    "\n",
    "        if re.match(\"doc\",l)!=None:\n",
    "            sequence.append(t) \n",
    "            label_seq.append(l) \n",
    "\n",
    "        elif l == \"ref_beg\":\n",
    "            i+=1\n",
    "            count_ref+=1\n",
    "            if sequence == []:\n",
    "                pass\n",
    "            else:\n",
    "                all_seq.append(sequence)\n",
    "                all_label_seq.append(label_seq)\n",
    "            sequence = []\n",
    "            label_seq = []\n",
    "    #         sequence.append(t)\n",
    "    #         label_seq.append(l)\n",
    "\n",
    "        elif l == \"ref_end\":\n",
    "            i+=1\n",
    "            sequence.append(t) \n",
    "            label_seq.append(l)\n",
    "            if sequence == []:\n",
    "                pass\n",
    "            else:\n",
    "                all_seq.append(sequence)\n",
    "                all_label_seq.append(label_seq)\n",
    "            sequence = []\n",
    "            label_seq = []\n",
    "        else:\n",
    "            sequence.append(t) \n",
    "            label_seq.append(l)\n",
    "\n",
    "    #     prev_label = l\n",
    "\n",
    "    if sequence == []:\n",
    "        pass\n",
    "    else:\n",
    "        all_seq.append(sequence)\n",
    "        all_label_seq.append(label_seq)\n",
    "    print(count_ref)     \n",
    "\n",
    "    \n",
    "    # first read in the template TEI. From there we will fill up the entries.\n",
    "#     tree = ET.parse(\"C:\\\\Masterarbeit\\\\Data\\\\template.tei\")\n",
    "    tree = ET.parse(\"\\template.tei\")\n",
    "\n",
    "    template_root = tree.getroot()\n",
    "    #################################\n",
    "    listBibl = template_root[1][0][0][0]\n",
    "    titleStmt = template_root[0][0][0]\n",
    "    # doc_title = template_root[0][0][0][0]\n",
    "    bx = 0\n",
    "    for i in range(len(all_label_seq)): # Gehe die einzelnen Referenzen durch\n",
    "        if len(re.findall(\"doc\" , str(all_label_seq[i])))>0:\n",
    "            doc_title = SubElement(titleStmt, \"title\", {\"level\":\"a\" , \"type\":\"main\"})\n",
    "            doc_title.text = all_seq[i][all_label_seq[i].index(\"doc_title\")]\n",
    "\n",
    "            doc_author = SubElement(titleStmt, \"author\")\n",
    "            for j in range(len(all_label_seq[i])): # gehe die einzelnen Labels der einzelnen Referenz durch\n",
    "                try:\n",
    "                # Author - labeled data\n",
    "                    if all_label_seq[i][j] =='doc_author':\n",
    "                        persName = SubElement(doc_author, \"persName\")\n",
    "                        persName.text = all_seq[i][j]\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "#             doc_author.text = all_seq[0][all_label_seq[i].index(\"doc_author\")]\n",
    "\n",
    "        else: \n",
    "            biblStruct = SubElement(listBibl, 'biblStruct',{\"xml:id\":\"b\"+str(bx)})\n",
    "            bx+=1\n",
    "            analytic = SubElement(biblStruct, 'analytic')\n",
    "            monogr = SubElement(biblStruct, 'monogr')\n",
    "            imprint = SubElement(monogr , 'imprint')\n",
    "            print(i)\n",
    "            labels = all_label_seq[i]\n",
    "            text = all_seq[i]\n",
    "\n",
    "            title_str = None\n",
    "            journal_str = None\n",
    "\n",
    "            # wollen pro Referenz nur ein \"Author\"-Value und darunter persName\n",
    "            if len(re.findall('author' , str(labels)))>0:\n",
    "                    author = SubElement(analytic, 'author')\n",
    "\n",
    "            for j in range(len(labels)): # gehe die einzelnen Labels der einzelnen Referenz durch\n",
    "                try:\n",
    "                # Author - labeled data\n",
    "                    if labels[j] =='author':\n",
    "                        persName = SubElement(author, \"persName\")\n",
    "                        persName.text = text[j]\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # Titel - labeled data\n",
    "                if labels[j] == \"title\" and title_str == None: ### Wir wollen alle Titel-labeled data zu einem String zusammenfassen\n",
    "#                     try:\n",
    "#                         if labels[j+1]==\"title\":\n",
    "#                             title_str = text[j]\n",
    "#                             for k , t in zip(labels[j+1:],text[j+1:]):\n",
    "#                                 if k==\"title\" and title_str[-1]!=\"-\":\n",
    "#                                     title_str = title_str + \" \" + t\n",
    "#                                     j+=1\n",
    "#                                 elif k==\"title\" and title_str[-1]==\"-\":\n",
    "#                                     title_str = title_str[0:-1] + t\n",
    "#                                     j+=1\n",
    "#                     except:\n",
    "#                         pass\n",
    "#                     else:\n",
    "                    title_str = text[j]\n",
    "\n",
    "                    title = SubElement(analytic, 'title', {\"level\":\"a\"})\n",
    "                    title.text = title_str.replace(\"\\n\",\" \")\n",
    "\n",
    "                # Journal - labeled data\n",
    "                if labels[j] == \"journal\" and journal_str == None:\n",
    "                    if labels[j+1]==\"journal\":\n",
    "                        journal_str = text[j]\n",
    "                        for k , t in zip(labels[j+1:],text[j+1:]):\n",
    "                            if k==\"journal\" and journal_str[-1]!=\"-\":\n",
    "                                journal_str = journal_str + \" \" + t\n",
    "                                j+=1\n",
    "                            elif k==\"journal\" and journal_str[-1]==\"-\":\n",
    "                                journal_str = journal_str[0:-1] + t\n",
    "                                j+=1\n",
    "                    else:\n",
    "                        journal_str = text[j]            \n",
    "                    title_j = SubElement(monogr, 'title', {\"level\":\"j\"})\n",
    "                    title_j.text = journal_str\n",
    "\n",
    "                # Volume - labeled data\n",
    "                if labels[j] == \"volume\":\n",
    "                    volume = SubElement(imprint , 'biblScope' , {'unit':'volume'})\n",
    "                    volume.text = text[j]\n",
    "\n",
    "                # Issue - labeled data\n",
    "                if labels[j] == \"issue\":\n",
    "                    issue = SubElement(imprint , 'biblScope' , {'unit':'issue'})\n",
    "                    issue.text = text[j]\n",
    "\n",
    "                # Year - labeled data\n",
    "                if labels[j] == \"year\":\n",
    "                    year = SubElement(imprint , 'date' , {'type':'published' , \"when\":text[j] })\n",
    "\n",
    "                # idno DOI - labeled data\n",
    "                if labels[j] == \"idno_doi\":\n",
    "                    issue = SubElement(imprint , 'idno' , {'type':'DOI'})\n",
    "                    issue.text = text[j]\n",
    "\n",
    "                 # idno other - labeled data\n",
    "                if labels[j] == \"idno_other\":\n",
    "                    issue = SubElement(imprint , 'idno' , {'type':'other'})\n",
    "                    issue.text = text[j]\n",
    "\n",
    "                # publisher - labeled data\n",
    "                if labels[j] == \"publisher\":\n",
    "                    publisher = SubElement(imprint , 'publisher')\n",
    "                    publisher.text = text[j]\n",
    "                    \n",
    "                # address - labeled data\n",
    "                if labels[j] == \"address\":\n",
    "                    address = SubElement(imprint , 'pubPlace')\n",
    "                    address.text = text[j]\n",
    "                    \n",
    "                # pages - labeled data\n",
    "                if labels[j] == \"pages\":\n",
    "                    pages = SubElement(imprint , 'biblScope' , {'unit':'pages'})\n",
    "                    pages.text = text[j]\n",
    "\n",
    "                \n",
    "#             # b_page & e_page - labeled data\n",
    "#             if len(re.findall('pages' , str(labels)))>1:\n",
    "#                 b_page = text[labels.index(\"pages\")]\n",
    "# #                 e_page = text[labels.index(\"pages\")]  \n",
    "#                 page = SubElement(imprint , 'biblScope' , {'unit':'page' , \"pages\":b_page})\n",
    "#             elif len(re.findall('page' , str(labels)))==1: \n",
    "#                 e_page = text[labels.index(\"pages\")]\n",
    "#                 page = SubElement(imprint , 'biblScope' , {'unit':'page' , \"pages\":e_page})\n",
    "                \n",
    "                \n",
    "                \n",
    "    mydata = str(prettify(template_root)).replace(\"ns0:\",\"\").replace(\":ns0\",\"\")\n",
    "#     myfile = open(os.path.join(\"C:/Masterarbeit/Data/manuel_annotated/TEI\",core_id + \".xml\"), \"w\",encoding=\"utf-8\")\n",
    "    myfile = open(os.path.join((\".\\Sequence-Labeling-for-Reference-Parsing-of-Cyrillic-Script-Scholarly-Data\\Real_annotated_data\\TEI\",core_id + \".xml\"), \"w\",encoding=\"utf-8\")\n",
    "\n",
    "    myfile.write(mydata)\n",
    "    myfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
